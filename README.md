# Pytorch Transformer

A learning implementation of the attention-only "Transformer" network by google. For [SF Deeplearners'](https://www.deeplearners.group/) discussion on attention networks.

> Based on the paper [Attention is All You Need](https://arxiv.org/pdf/1706.03762v4.pdf)

> Google's original implementation in TensorFlow [here](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py)

## Implementation

Notes on the implementation are in [a jupyter notebook](./research/implementation_notes.ipynb), if you'd like to follow along with my (scattered) thought process.

**NB: This is the only place the implementation is currently. Making an actual module is a very soon TODO. Sorry.**
